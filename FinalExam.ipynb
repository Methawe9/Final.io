{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_video_source = cv2.VideoCapture(\"videos/stereo/left_output.avi\")\n",
    "original_train_model = cv2.imread(\"images/final_exam/Templates/Template-1.png\")\n",
    "grayscale_train_model = cv2.cvtColor(original_train_model, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "x_coordinate, y_coordinate, z_coordinate = 0, 0, 0\n",
    "float_width, float_height = [float(sizes) for sizes in [0, 0]]\n",
    "\n",
    "video_capture = orginal_video_source\n",
    "if video_capture.isOpened():\n",
    "    float_width = video_capture.get(3)\n",
    "    float_height = video_capture.get(4)\n",
    "\n",
    "divide_width, divide_height = [float(divide) for divide in [float_width / 2, float_height / 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectDetection(train_image, grayscale_train_image, query_image, grayscale_query_image):\n",
    "    train_image_keypoints, train_image_descriptors = sift.detectAndCompute(grayscale_train_image, None)\n",
    "    query_image_keypoints, query_image_descriptors = sift.detectAndCompute(grayscale_query_image, None)\n",
    "\n",
    "    matches = bf.knnMatch(train_image_descriptors, query_image_descriptors, k=2)\n",
    "    good_matches = list()\n",
    "    good_matches_list = list()\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "            good_matches_list.append([m])\n",
    "\n",
    "    if len(good_matches) > 10:\n",
    "        src_pts = np.float32([ train_image_keypoints[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([ query_image_keypoints[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)\n",
    "\n",
    "        HOMOGRAPHY = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 0.7)\n",
    "\n",
    "        h, w = train_image.shape[:2]\n",
    "        train_image_box = np.float32([\n",
    "            [0, 0], [0, h-1], [w-1, h-1], [w-1, 0]\n",
    "        ]).reshape(-1, 1, 2)\n",
    "        train_image_transformed_box = cv2.perspectiveTransform(train_image_box, HOMOGRAPHY)\n",
    "\n",
    "        detected_image = cv2.polylines(query_image, [np.int32(train_image_transformed_box)], True, (255, 0, 255), 3, cv2.LINE_AA)\n",
    "        x_coordinate = train_image_transformed_box[0][0]\n",
    "        y_coordinate = train_image_transformed_box[1][0]\n",
    "\n",
    "        first_popric = train_image_transformed_box[0]\n",
    "        second_popric = train_image_transformed_box[1]\n",
    "        total_popric = second_popric[0] - first_popric[0]\n",
    "\n",
    "        cv2.putText(query_image, \"x: {}, y: {}, z: {}\".format(int(x_coordinate[0] - divide_width), int(y_coordinate[1] - divide_height), int(total_popric[1])), (50, 60), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        return detected_image\n",
    "    else:\n",
    "        print(\"Keypoints not enough ...\")\n",
    "        return query_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'perspectiveTransform'\n> Overload resolution failed:\n>  - m is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'm'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17616/2776619361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgrayscale_query_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Object\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjectDetection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_train_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale_train_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale_query_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17616/1607171241.py\u001b[0m in \u001b[0;36mobjectDetection\u001b[1;34m(train_image, grayscale_train_image, query_image, grayscale_query_image)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         ]).reshape(-1, 1, 2)\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtrain_image_transformed_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHOMOGRAPHY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdetected_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolylines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image_transformed_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'perspectiveTransform'\n> Overload resolution failed:\n>  - m is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'm'\n"
     ]
    }
   ],
   "source": [
    "while video_capture.isOpened():\n",
    "    ret, query_image = video_capture.read()\n",
    "    grayscale_query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2GRAY)\n",
    "    if ret:\n",
    "        cv2.imshow(\"Object\", objectDetection(original_train_model, grayscale_train_model, query_image, grayscale_query_image))\n",
    "        if cv2.waitKey(int(1000 / 30)) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
